{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a877dc8f-6c63-42e8-befd-cec16db1f6bc",
   "metadata": {},
   "source": [
    "# Automated Web Scraper: Live Bitcoin Price Tracker (Beginner Project)\n",
    "\n",
    "This project was built as part of my Python learning process.  \n",
    "I used Selenium, BeautifulSoup, and regular expressions to scrape the live Bitcoin price from CoinMarketCap.  \n",
    "\n",
    "The goal of this project was to:\n",
    "- Scrape the live Bitcoin price every 7 seconds for 35 seconds (5 scrapes total)\n",
    "- Store the results in a CSV file for later analysis\n",
    "- Track and display the total price change across the scraping period\n",
    "\n",
    "Basic error handling is included to skip failed scrapes and ensure the script completes cleanly even if the page fails to load or the price is unavailable.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "The purpose of this project was to:\n",
    "- Load the CoinMarketCap Bitcoin page using Selenium\n",
    "- Wait for the page to fully render dynamic content\n",
    "- Parse the page HTML using BeautifulSoup\n",
    "- Extract the price using a regular expression to handle number formatting variations\n",
    "- Save each valid scrape (timestamp, price) to a CSV file\n",
    "- Track valid prices across all scrapes to report total price change\n",
    "\n",
    "---\n",
    "\n",
    "## Libraries and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d12a4474-8282-421d-858e-12f5785a9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc1e95-9c9a-4d45-b60b-f6669aa28910",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "Approach:\n",
    "\n",
    "- Use Selenium to load the CoinMarketCap Bitcoin page\n",
    "- Wait for dynamic content to load fully\n",
    "- Parse the HTML content using BeautifulSoup\n",
    "- Locate and extract:\n",
    "    - The coin name (`<span>` with string 'Bitcoin')\n",
    "    - The price (`<span>` with `data-test=\"text-cdp-price-display\"` attribute)\n",
    "- Use a regular expression to safely extract the numeric portion of the price\n",
    "- Store each valid scrape in a CSV file\n",
    "- Append valid prices to an in-memory list for tracking\n",
    "- Repeat the scrape process 5 times (one scrape every 7 seconds)\n",
    "- After all scrapes:\n",
    "    - Calculate and display the total price difference between the first and last valid scrapes\n",
    "    - Gracefully handle missing prices to avoid crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ab133-02f6-4b84-8c80-d0ab6876f7b3",
   "metadata": {},
   "source": [
    "## Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8fea85-151b-4964-9bbc-d21e3d79861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape 1 of 5\n",
      "[2025-06-09 19:19:01] Scraped Bitcoin | Price: $110,020.88\n",
      "Scrape 2 of 5\n",
      "[2025-06-09 19:19:18] Scraped Bitcoin | Price: $110,055.11\n",
      "Scrape 3 of 5\n",
      "[2025-06-09 19:19:34] Scraped Bitcoin | Price: $110,049.44\n",
      "Scrape 4 of 5\n",
      "[2025-06-09 19:19:52] Scraped Bitcoin | Price: $110,043.73\n",
      "Scrape 5 of 5\n",
      "[2025-06-09 19:20:09] Scraped Bitcoin | Price: $110,026.61\n",
      "\n",
      "====== FINAL REPORT ======\n",
      "Total Scraped Bitcoin Difference: $5.73\n"
     ]
    }
   ],
   "source": [
    "# It makes a lot of sense for this to be put all of this within a function\n",
    "def automated_crypto_pull():\n",
    "    # Path to your chromedriver\n",
    "    service = Service(r\"C:\\Users\\jrwie\\OneDrive\\Desktop\\Data Stuffs\\Python_Things\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    \n",
    "    # Step 1: Go to the live Bitcoin price page\n",
    "    driver.get(\"https://coinmarketcap.com/currencies/bitcoin/\")\n",
    "    time.sleep(5)  # Wait for JavaScript to finish loading\n",
    "    \n",
    "    # Step 2: Parse the rendered HTML\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Step 3: Extract the coin name and price\n",
    "    crypto_name = soup.find('span', string='Bitcoin').text\n",
    "    price = soup.find('span', attrs={'data-test': 'text-cdp-price-display'}).text\n",
    "    \n",
    "    # Use regex to safely extract price\n",
    "    import re\n",
    "    price_match = re.search(r'[\\d,.]+', price)\n",
    "    if price_match:\n",
    "        final_price_str = price_match.group().replace(',', '')\n",
    "        formatted_price = f\"${float(final_price_str):,.2f}\"\n",
    "        returned_price = float(final_price_str)\n",
    "    else:\n",
    "        final_price_str = 'N/A'\n",
    "        formatted_price = 'N/A'\n",
    "        returned_price = None\n",
    "    \n",
    "    # Step 4: Store in DataFrame\n",
    "    date_time = datetime.now()\n",
    "    formatted_time = date_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    crypto_dict = {\n",
    "        'Crypto Name': [crypto_name],\n",
    "        'Price': [final_price_str],\n",
    "        'TimeStamp': [date_time]\n",
    "    }\n",
    "    df = pd.DataFrame(crypto_dict)\n",
    "\n",
    "    # Step 5: Clean up\n",
    "    driver.quit()\n",
    "    \n",
    "    # Step 6: Write to CSV\n",
    "    output_path = r\"C:\\Users\\jrwie\\OneDrive\\Desktop\\Data Stuffs\\Python_Things\\Crypto_Web_Puller\\Crypto_Automated_Pull.csv\"\n",
    "    columns = ['Crypto Name', 'Price', 'TimeStamp']\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        df.to_csv(output_path, mode='a', header=False, index=False, columns=columns)\n",
    "    else:\n",
    "        df.to_csv(output_path, index=False, columns=columns)\n",
    "    \n",
    "    # Final print\n",
    "    print(f\"[{formatted_time}] Scraped {crypto_name} | Price: {formatted_price}\")\n",
    "    \n",
    "    # Return the scraped price (float or None)\n",
    "    return returned_price\n",
    "\n",
    "# Now that the function is defined, we can do a for loop\n",
    "# Define empty list to track prices\n",
    "scraped_prices = []\n",
    "\n",
    "# Run the scraper 5 times\n",
    "for i in range(5):\n",
    "    print(f\"Scrape {i+1} of 5\")\n",
    "    latest_price = automated_crypto_pull()  # Capture return value!\n",
    "    if latest_price is not None:\n",
    "        scraped_prices.append(latest_price)\n",
    "    else:\n",
    "        print(\"Skipping this scrape due to missing price.\")\n",
    "    time.sleep(7)\n",
    "\n",
    "# After loop, calculate difference if possible\n",
    "if len(scraped_prices) >= 2:\n",
    "    price_difference = scraped_prices[-1] - scraped_prices[0]\n",
    "    formatted_difference = f\"${price_difference:,.2f}\"\n",
    "    print(\"\\n====== FINAL REPORT ======\")\n",
    "    print(f\"Total Scraped Bitcoin Difference: {formatted_difference}\")\n",
    "else:\n",
    "    print(\"\\n====== FINAL REPORT ======\")\n",
    "    print(\"Not enough valid scrapes to compute difference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d3a06-c6a6-4a3f-ba85-1620c1c62254",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Potential improvements:\n",
    "- Add more robust error handling and logging\n",
    "- Handle dynamic page structure changes more gracefully (e.g., changes to class names or page layout)\n",
    "- Automatically adjust scrape frequency based on actual page load times\n",
    "- Extend the scraper to run over longer periods and analyze longer-term trends\n",
    "- Visualize the price trend within the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d38539-95bb-4c7a-8730-edaf8a546c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3821d3e-11b6-4fbf-bdef-99e3c70ec269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9707d22-09ff-441c-9f85-8f70563dd272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
