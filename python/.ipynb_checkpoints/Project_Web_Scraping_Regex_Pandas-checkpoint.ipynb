{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a027ad0a-9eca-4349-b3c9-073622d52c85",
   "metadata": {},
   "source": [
    "# Web Scraping and Text Cleaning: MLK Jr. \"I Have a Dream\" Speech (Beginner Project)\n",
    "\n",
    "This project was built as part of my Python learning process.  \n",
    "I used `requests`, `BeautifulSoup`, `re` (regular expressions), and `pandas` to scrape and analyze the full text of Martin Luther King Jr.'s \"I Have a Dream\" speech from a sample webpage.  \n",
    "\n",
    "The goal of this project was to:\n",
    "- Scrape the full text of the speech from the target webpage\n",
    "- Clean and standardize the text using regular expressions\n",
    "- Perform word frequency analysis\n",
    "- Store the results in a CSV file for further analysis or visualization\n",
    "\n",
    "This is a beginner project — not a production-grade scraper — and is focused on practicing text extraction, data cleaning, and basic natural language processing (NLP) techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6fd47a-c13d-4bcc-a220-54cda52b0dea",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3202249f-9265-43d7-9919-faf55005d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f39e79-5b7f-4f7d-adc9-bc2c1d8d231e",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "Approach:\n",
    "\n",
    "- Use `requests` to send an HTTP GET request to the target webpage\n",
    "- Parse the HTML using `BeautifulSoup`\n",
    "- Extract paragraph text (`<p>` tags) and combine the content into a single string\n",
    "- Perform initial text cleaning:\n",
    "    - Remove line breaks and unwanted escape characters\n",
    "    - Normalize apostrophes\n",
    "- Convert all text to lowercase\n",
    "- Use regular expressions to:\n",
    "    - Remove punctuation (while keeping apostrophes inside words)\n",
    "    - Tokenize the text into individual words\n",
    "- Build a Pandas DataFrame to store the words\n",
    "- Perform word frequency analysis using `value_counts()`\n",
    "- Save the cleaned word counts to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f307de-cab2-4c59-9165-e5108d5cfeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "      word  count\n",
      "0      the     54\n",
      "1       of     49\n",
      "2       to     29\n",
      "3      and     27\n",
      "4        a     20\n",
      "5       in     17\n",
      "6       be     16\n",
      "7     will     16\n",
      "8  freedom     13\n",
      "9       we     13\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Scrape the webpage\n",
    "url = 'http://www.analytictech.com/mb021/mlk.htm'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# Step 2: Extract paragraph text and combine\n",
    "mlkjr_speech = soup.find_all('p')\n",
    "speech_combined = [p.text.strip() for p in mlkjr_speech]\n",
    "string_speech = ' '.join(speech_combined)\n",
    "\n",
    "# Step 3: Initial cleaning\n",
    "a_lil_clean = string_speech.replace('\\r\\n', ' ').replace(r\"\\'\", \"'\")\n",
    "\n",
    "# Optional: Quick checks (can be removed if desired)\n",
    "print(\"we're\" in a_lil_clean)  # Should be True\n",
    "print(\"God's\" in a_lil_clean)  # Should be True\n",
    "\n",
    "# Step 4: Lowercase everything\n",
    "cleaned = a_lil_clean.lower()\n",
    "\n",
    "# Step 5: Remove punctuation, keep apostrophes within words\n",
    "cleaned = re.sub(r\"[^\\w\\s']+\", '', cleaned)\n",
    "\n",
    "# Step 6: Tokenize (split into words)\n",
    "cleaned_words = cleaned.split()\n",
    "\n",
    "# Step 7: Build DataFrame and count word frequencies\n",
    "df = pd.DataFrame(cleaned_words, columns=['word'])\n",
    "df = df.value_counts().reset_index(name='count')\n",
    "df.columns = ['word', 'count']\n",
    "\n",
    "# Step 8: Show top 10 most common words\n",
    "print(df.head(10))\n",
    "\n",
    "# Step 9: Export to CSV\n",
    "df.to_csv(r'C:\\Users\\jrwie\\OneDrive\\Desktop\\Data Stuffs\\Analyst_Builder\\Python\\Exports\\MLKjr_speech_scraped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e244cc41-3731-433c-8564-68b507664562",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Potential improvements:\n",
    "- Perform deeper text cleaning (e.g., stopword removal)\n",
    "- Visualize the word frequencies with a bar chart or word cloud\n",
    "- Compare the word frequency of this speech to other famous speeches\n",
    "- Explore more advanced NLP techniques (lemmatization, part-of-speech tagging)\n",
    "- Build a reusable text analysis pipeline for other scraped texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac4c2a3-bf06-4ca8-98b6-2d38800f7c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
